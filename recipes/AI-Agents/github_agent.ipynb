{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "introduction"
      },
      "source": [
        "# Building a GitHub Agent with LangGraph and LangChain\n",
        "\n",
        "This notebook guides you through building an intelligent agent that can interact with GitHub repositories. Using LangGraph, LangChain, and IBM's Granite LLM, you'll create an agent capable of performing various GitHub operations through natural language instructions.\n",
        "\n",
        "## What You'll Learn\n",
        "- How to set up API connections to GitHub\n",
        "- How to serve and interact with an LLM (IBM Granite)\n",
        "- How to create tools that interact with GitHub's API\n",
        "- How to build a ReAct agent that can reason about GitHub tasks\n",
        "\n",
        "## Prerequisites\n",
        "- GitHub account with a repository you want the agent to access\n",
        "- Either a local Ollama server or a Replicate API token\n",
        "- Basic understanding of Python and LLMs\n",
        "\n",
        "Let's start by insuring we are using Python 3.10 or 3.11"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "import sys\n",
        "assert sys.version_info >= (3, 10) and sys.version_info < (3, 12), \"Use Python 3.10 or 3.11 to run this notebook.\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "and Installing some dependencies:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "wHsVa-PXBhfz"
      },
      "outputs": [],
      "source": [
        "! pip install langgraph\n",
        "! pip install --upgrade --quiet pygithub langchain-community replicate\n",
        "! pip install git+https://github.com/ibm-granite-community/utils \\\n",
        "  langchain_ollama"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Connecting to GitHub\n",
        "\n",
        "For your agent to interact with GitHub, it needs proper authentication. We'll use GitHub Apps for this purpose, which provides a secure way to access repositories.\n",
        "\n",
        "### Setting Up Your GitHub App\n",
        "\n",
        "1. Follow the instructions [here](https://docs.github.com/en/apps/creating-github-apps/registering-a-github-app/registering-a-github-app) to create a GitHub App\n",
        "2. Configure the following permissions for your app:\n",
        "   - Repository contents: Read & Write\n",
        "   - Issues: Read & Write\n",
        "   - Pull requests: Read & Write\n",
        "3. Generate a private key for your app\n",
        "4. Install the app to your repository\n",
        "\n",
        "After setting up your GitHub App, you'll need three pieces of information:\n",
        "- Your repository name in the format `username/repo-name`\n",
        "- The private key file (downloaded when you created the app)\n",
        "- The GitHub App ID (found in your app's settings)\n",
        "\n",
        "Let's set these as environment variables:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TxrAl1JM9Wzi"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from getpass import getpass\n",
        "\n",
        "# Setup GitHub credentials\n",
        "os.environ[\"GITHUB_REPOSITORY\"] = \"your/githubrepo\"\n",
        "os.environ[\"GITHUB_APP_PRIVATE_KEY\"] = \"your/private_key.pem\"\n",
        "os.environ[\"GITHUB_APP_ID\"] = \"GithubAppID\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setting Up the LLM\n",
        "\n",
        "Our agent needs an LLM to generate responses and make decisions. We'll use IBM's Granite model, which can be served in two ways:\n",
        "\n",
        "1. **Local deployment via Ollama**: Faster and free, but requires local resources\n",
        "2. **Cloud deployment via Replicate**: Accessible from anywhere, but requires an API token\n",
        "\n",
        "The code below will try to use a local Ollama server first, and if that's not available, it will fall back to Replicate.\n",
        "\n",
        "### Setting Up Ollama (Optional)\n",
        "If you want to use Ollama:\n",
        "1. Install Ollama from [https://ollama.ai/](https://ollama.ai/)\n",
        "2. Run `ollama pull granite3.1-dense:8b` to download the model\n",
        "\n",
        "### Setting Up Replicate\n",
        "If you want to use Replicate:\n",
        "1. Create an account at [https://replicate.com/](https://replicate.com/)\n",
        "2. Generate an API token at [https://replicate.com/account/api-tokens](https://replicate.com/account/api-tokens)\n",
        "\n",
        "Let's set up our LLM:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WwOeYK5Hdm6q"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import requests\n",
        "from langchain_ollama.llms import OllamaLLM\n",
        "from langchain_community.llms import Replicate\n",
        "from ibm_granite_community.notebook_utils import get_env_var\n",
        "from ibm_granite_community.notebook_utils import get_env_var\n",
        "\n",
        "# Setup Replicate API token (you need to provide this)\n",
        "replicate_api_token = getpass(\"Enter your Replicate API token: \")\n",
        "os.environ[\"REPLICATE_API_TOKEN\"] = replicate_api_token\n",
        "\n",
        "try: # Look for a locally accessible Ollama server for the model\n",
        "    response = requests.get(os.getenv(\"OLLAMA_HOST\", \"http://127.0.0.1:11434\"))\n",
        "    llm = OllamaLLM(\n",
        "        model=\"granite3.1-dense:8b\",\n",
        "        num_ctx=65536, # 64K context window\n",
        "    )\n",
        "# Initialize Replicate\n",
        "except Exception:\n",
        "  llm = Replicate(\n",
        "    model =\"ibm-granite/granite-3.1-8b-instruct\",\n",
        "      replicate_api_token = get_env_var('REPLICATE_API_TOKEN'),\n",
        "      model_kwargs={\n",
        "          \"max_tokens\": 2000, # Set the maximum number of tokens to generate as output.\n",
        "          \"min_tokens\": 200, # Set the minimum number of tokens to generate as output.\n",
        "          \"temperature\": 0.75,\n",
        "          \"presence_penalty\": 0,\n",
        "          \"frequency_penalty\": 0,\n",
        "    }\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Creating the GitHub Toolkit\n",
        "\n",
        "Now that we have our GitHub credentials and LLM set up, let's create the GitHub toolkit. This toolkit provides a set of tools that our agent can use to interact with GitHub.\n",
        "\n",
        "LangChain provides a convenient `GitHubToolkit` class that wraps around the GitHub API. Let's initialize it:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L6xj5d9L4LoQ"
      },
      "outputs": [],
      "source": [
        "from langchain_community.agent_toolkits.github.toolkit import GitHubToolkit\n",
        "from langchain_community.utilities.github import GitHubAPIWrapper\n",
        "\n",
        "github = GitHubAPIWrapper()\n",
        "toolkit = GitHubToolkit.from_github_api_wrapper(github)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Exploring Available GitHub Tools\n",
        "\n",
        "Let's explore the tools that are available in our GitHub toolkit. Each tool represents a specific action our agent can take on GitHub, such as creating an issue, commenting on a pull request, or reading file contents.\n",
        "\n",
        "This step helps us understand what our agent is capable of doing:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zaEfjSg9_d3g"
      },
      "outputs": [],
      "source": [
        "tools = toolkit.get_tools()\n",
        "\n",
        "for tool in tools:\n",
        "    print(tool.name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Testing the LLM\n",
        "\n",
        "Before building our agent, it's a good idea to test the LLM to make sure it's working properly. This simple test ensures that we can connect to either Ollama or Replicate and that the model responds as expected:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "test_llm_cell"
      },
      "outputs": [],
      "source": [
        "# Test the LLM to make sure it's working\n",
        "llm.invoke(\"Hello, what can you help me with today?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Displaying Available GitHub Tools with Descriptions\n",
        "\n",
        "Now let's get a better understanding of each tool by displaying not just their names, but also their descriptions. This will help us understand what each tool does and how our agent might use them:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sHkCEGi9-I5M"
      },
      "outputs": [],
      "source": [
        "tools = toolkit.get_tools()\n",
        "print(\"Available tools:\")\n",
        "for tool in tools:\n",
        "    print(f\"- {tool.name}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Building the ReAct Agent\n",
        "\n",
        "Now we're ready to build our GitHub agent! We'll use the ReAct (Reasoning and Acting) framework, which allows our agent to:\n",
        "\n",
        "1. Think about what it should do (Reasoning)\n",
        "2. Take an action using one of the GitHub tools (Acting)\n",
        "3. Observe the result of that action\n",
        "4. Reason about what to do next based on those observations\n",
        "\n",
        "This approach allows the agent to break down complex GitHub tasks into a series of steps.\n",
        "\n",
        "We'll start by defining a prompt template that instructs the LLM on how to use the ReAct framework:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XhTtEHeNAtxa"
      },
      "outputs": [],
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "template = \"\"\"You are a helpful GitHub assistant who can perform various actions on GitHub repositories.\n",
        "You have access to the following tools:\n",
        "\n",
        "{tools}\n",
        "\n",
        "Use the following format:\n",
        "\n",
        "Question: the input question you must answer\n",
        "Thought: you should always think about what to do\n",
        "Action: the action to take, must be one of [{tool_names}]\n",
        "Action Input: input passed to tool\n",
        "Observation: action result\n",
        "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
        "Thought: I now know the final answer\n",
        "Final Answer: the final answer to the original input question\n",
        "\n",
        "Begin!\n",
        "\n",
        "Question: {input}\n",
        "Thought: {agent_scratchpad}\n",
        "\"\"\"\n",
        "\n",
        "# Create the prompt template\n",
        "prompt = PromptTemplate(\n",
        "    template=template,\n",
        "    input_variables=[\"input\", \"agent_scratchpad\"],\n",
        "    partial_variables={\n",
        "        \"tools\": lambda x: format_tool_string(tools),\n",
        "        \"tool_names\": lambda x: \", \".join([tool.name for tool in tools]),\n",
        "    },\n",
        ")\n",
        "\n",
        "# Helper function to format tools\n",
        "def format_tool_string(tools):\n",
        "    return \"\\n\".join([f\"{tool.name}: {tool.description}\" for tool in tools])\n",
        "\n",
        "# Create a memory to maintain conversation context\n",
        "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
        "\n",
        "# Instantiate the ReAct agent using LangChain's create_react_agent\n",
        "agent = create_react_agent(\n",
        "    llm,\n",
        "    tools,\n",
        "    prompt,\n",
        ")\n",
        "\n",
        "# Create an agent executor with the ReAct agent\n",
        "agent_executor = AgentExecutor(\n",
        "    agent=agent,\n",
        "    tools=tools,\n",
        "    memory=memory,\n",
        "    verbose=True,\n",
        "    handle_parsing_errors=True,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Creating a Helper Function to Run the Agent\n",
        "\n",
        "Now that our agent is set up, let's create a helper function that makes it easy to run the agent with different queries:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tjbm-dtjGl1U"
      },
      "outputs": [],
      "source": [
        "def run_github_agent(query):\n",
        "    \"\"\"Run the GitHub agent with a user query.\"\"\"\n",
        "    result = agent_executor.invoke({\"input\": query})\n",
        "    return result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Testing the GitHub Agent\n",
        "\n",
        "Now that our agent is fully set up, let's test it with a simple query. This example asks the agent to count the number of issues in the repository:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xAFJHz8FDnhK"
      },
      "outputs": [],
      "source": [
        "result = run_github_agent(\"how many issues are there\")\n",
        "print(result[\"output\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Example Use Cases\n",
        "\n",
        "Here are some example queries you can try with your GitHub agent:\n",
        "\n",
        "```python\n",
        "# Get information about repositories\n",
        "run_github_agent(\"List all the files in the repository\")\n",
        "run_github_agent(\"What are the most recent commits?\")\n",
        "\n",
        "# Work with issues\n",
        "run_github_agent(\"Create a new issue titled 'Update documentation' with description 'We need to update the README file'\")\n",
        "run_github_agent(\"List all open issues\")\n",
        "run_github_agent(\"Close issue #1\")\n",
        "\n",
        "# Work with pull requests\n",
        "run_github_agent(\"List all open pull requests\")\n",
        "run_github_agent(\"Comment on pull request #2 saying 'Looks good, approved!'\")\n",
        "\n",
        "# Work with file contents\n",
        "run_github_agent(\"What's in the README.md file?\")\n",
        "run_github_agent(\"Create a new file called 'hello.txt' with content 'Hello, world!'\")\n",
        "```\n",
        "\n",
        "Feel free to experiment with different queries based on your repository's contents and what you want to accomplish!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Conclusion\n",
        "\n",
        "Congratulations! You've built a functional GitHub agent that can interact with your repository using natural language instructions. This agent demonstrates the power of combining LLMs with API tools to create useful AI assistants.\n",
        "\n",
        "### What You've Learned\n",
        "- How to set up GitHub App authentication\n",
        "- How to connect to and utilize an LLM (IBM Granite)\n",
        "- How to create a ReAct agent that can reason about and execute GitHub operations\n",
        "- How to use LangChain and LangGraph to create an AI agent with tool-using capabilities\n",
        "\n",
        "### Next Steps\n",
        "- Try more complex queries and see how the agent handles them\n",
        "- Add more specialized tools for specific GitHub operations\n",
        "- Integrate this agent with other services like Slack or Discord\n",
        "- Refine the agent's prompt to make it better at specific tasks"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
